{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":510,"status":"ok","timestamp":1673087747526,"user":{"displayName":"Reni Anggraeni","userId":"17139821022825599648"},"user_tz":-420},"id":"9BkKKnMWSuk0","outputId":"0fd19ac0-140a-4ff8-ce8e-f430aa24f77f"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","import string\n","import random\n","import nltk\n","nltk.download('omw-1.4')\n","import numpy as num\n","from nltk.stem import WordNetLemmatizer # It has the ability to lemmatize.\n","import tensorflow as tensorF # A multidimensional array of elements is represented by this symbol.\n","from tensorflow.keras import Sequential # Sequential groups a linear stack of layers into a tf.keras.Model\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","nltk.download(\"punkt\")# required package for tokenization\n","nltk.download(\"wordnet\")# word database"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1673087751045,"user":{"displayName":"Reni Anggraeni","userId":"17139821022825599648"},"user_tz":-420},"id":"ekI_nnHeTiea"},"outputs":[],"source":["ourData = {\"ourIntents\": [\n","\n","             {\"tag\": \"jam buka\",\n","              \"patterns\": [\"Setiap jam berapa toko online ini dibuka?\",\"Kapan buka toko ini?\"],\n","              \"responses\": [\"Toko online ini buka setiap jam 09.00 sampai 21.00\"]\n","             },\n","              {\"tag\": \"alamat toko\",\n","              \"patterns\": [ \"Dimana kah alamat toko ini?\",\"dimana lokasi toko?\"],\n","              \"responses\": [\"Lokasi Jl. Cisinga, Kp. Siwaru, Ds. Mekarjaya, Kec. Padakembang, Kab. Tasikmalaya\"],\n","             },\n","              {\"tag\": \"harga produk\",\n","              \"patterns\": [ \"Dari Harga Berapa harga produk yang ditawarkan di toko online ini?\"],\n","              \"responses\": [\"Toko kami menawarkan beberapa produk dengan kualitas baik dengan harga terjangkau, mulai dari 15.000\"]\n","             },\n","             {\"tag\": \"ketersedian produk\",\n","              \"patterns\": [\"Bagaimana ketersedian produk terutama dalam produk Cosmetik?\"],\n","              \"responses\": [\"Toko kami memiliki ketersedian produk mulai dari cosmetic, pakaian, alat-alat rumah dll\"]\n","             }\n","\n","]}"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1673087753880,"user":{"displayName":"Reni Anggraeni","userId":"17139821022825599648"},"user_tz":-420},"id":"x0Y-PCjujLOp"},"outputs":[],"source":["lm = WordNetLemmatizer() #for getting words\n","# lists\n","ourClasses = []\n","newWords = []\n","documentX = []\n","documentY = []\n","# Each intent is tokenized into words and the patterns and their associated tags are added to their respective lists.\n","for intent in ourData[\"ourIntents\"]:\n","    for pattern in intent[\"patterns\"]:\n","        ournewTkns = nltk.word_tokenize(pattern)# tokenize the patterns\n","        newWords.extend(ournewTkns)# extends the tokens\n","        documentX.append(pattern)\n","        documentY.append(intent[\"tag\"])\n","\n","\n","    if intent[\"tag\"] not in ourClasses:# add unexisting tags to their respective classes\n","        ourClasses.append(intent[\"tag\"])\n","\n","newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation] # set words to lowercase if not in punctuation\n","newWords = sorted(set(newWords))# sorting words\n","ourClasses = sorted(set(ourClasses))# sorting classes"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1673087757676,"user":{"displayName":"Reni Anggraeni","userId":"17139821022825599648"},"user_tz":-420},"id":"PuJniPtllMYZ"},"outputs":[],"source":["trainingData = [] # training list array\n","outEmpty = [0] * len(ourClasses)\n","# bow model\n","for idx, doc in enumerate(documentX):\n","    bagOfwords = []\n","    text = lm.lemmatize(doc.lower())\n","    for word in newWords:\n","        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n","\n","    outputRow = list(outEmpty)\n","    outputRow[ourClasses.index(documentY[idx])] = 1\n","    trainingData.append([bagOfwords, outputRow])\n","\n","random.shuffle(trainingData)\n","trainingData = num.array(trainingData, dtype=object)# coverting our data into an array afterv shuffling\n","\n","x = num.array(list(trainingData[:, 0]))# first trainig phase\n","y = num.array(list(trainingData[:, 1]))# second training phase"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4484,"status":"ok","timestamp":1673087766230,"user":{"displayName":"Reni Anggraeni","userId":"17139821022825599648"},"user_tz":-420},"id":"49nIzx79lO6S","outputId":"b8cc9940-187c-487c-f56a-371a85be225e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             (None, 128)               3200      \n","                                                                 \n"," dropout_2 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_3 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_5 (Dense)             (None, 4)                 260       \n","                                                                 \n","=================================================================\n","Total params: 11,716\n","Trainable params: 11,716\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/200\n","1/1 [==============================] - 1s 502ms/step - loss: 1.6201 - accuracy: 0.1667\n","Epoch 2/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.3767 - accuracy: 0.3333\n","Epoch 3/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.2645 - accuracy: 0.3333\n","Epoch 4/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.1180 - accuracy: 0.6667\n","Epoch 5/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.9391 - accuracy: 0.6667\n","Epoch 6/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.6899 - accuracy: 1.0000\n","Epoch 7/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.8139 - accuracy: 0.8333\n","Epoch 8/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.6712 - accuracy: 0.8333\n","Epoch 9/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 1.0000\n","Epoch 10/200\n","1/1 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 1.0000\n","Epoch 11/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.3082 - accuracy: 1.0000\n","Epoch 12/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.1475 - accuracy: 1.0000\n","Epoch 13/200\n","1/1 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 1.0000\n","Epoch 14/200\n","1/1 [==============================] - 0s 6ms/step - loss: 0.1460 - accuracy: 1.0000\n","Epoch 15/200\n","1/1 [==============================] - 0s 6ms/step - loss: 0.0767 - accuracy: 1.0000\n","Epoch 16/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 1.0000\n","Epoch 17/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 1.0000\n","Epoch 18/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000\n","Epoch 19/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 20/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 21/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.1281 - accuracy: 1.0000\n","Epoch 22/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.2286 - accuracy: 0.8333\n","Epoch 23/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 1.0000\n","Epoch 24/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000\n","Epoch 25/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 26/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 1.0000\n","Epoch 27/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 28/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0541 - accuracy: 1.0000\n","Epoch 29/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.7055e-04 - accuracy: 1.0000\n","Epoch 30/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 31/200\n","1/1 [==============================] - 0s 7ms/step - loss: 6.7913e-04 - accuracy: 1.0000\n","Epoch 32/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 33/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.0840e-04 - accuracy: 1.0000\n","Epoch 34/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 35/200\n","1/1 [==============================] - 0s 7ms/step - loss: 3.3119e-05 - accuracy: 1.0000\n","Epoch 36/200\n","1/1 [==============================] - 0s 7ms/step - loss: 3.0178e-05 - accuracy: 1.0000\n","Epoch 37/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.2516e-04 - accuracy: 1.0000\n","Epoch 38/200\n","1/1 [==============================] - 0s 7ms/step - loss: 4.4599e-05 - accuracy: 1.0000\n","Epoch 39/200\n","1/1 [==============================] - 0s 7ms/step - loss: 7.7667e-05 - accuracy: 1.0000\n","Epoch 40/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.1285e-05 - accuracy: 1.0000\n","Epoch 41/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.1855e-06 - accuracy: 1.0000\n","Epoch 42/200\n","1/1 [==============================] - 0s 7ms/step - loss: 3.4154e-04 - accuracy: 1.0000\n","Epoch 43/200\n","1/1 [==============================] - 0s 8ms/step - loss: 6.3805e-05 - accuracy: 1.0000\n","Epoch 44/200\n","1/1 [==============================] - 0s 8ms/step - loss: 9.5366e-06 - accuracy: 1.0000\n","Epoch 45/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.0091e-04 - accuracy: 1.0000\n","Epoch 46/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.2646e-04 - accuracy: 1.0000\n","Epoch 47/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.9605e-07 - accuracy: 1.0000\n","Epoch 48/200\n","1/1 [==============================] - 0s 9ms/step - loss: 4.7340e-05 - accuracy: 1.0000\n","Epoch 49/200\n","1/1 [==============================] - 0s 13ms/step - loss: 4.4107e-06 - accuracy: 1.0000\n","Epoch 50/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 51/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 52/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.8809e-06 - accuracy: 1.0000\n","Epoch 53/200\n","1/1 [==============================] - 0s 8ms/step - loss: 9.7465e-05 - accuracy: 1.0000\n","Epoch 54/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.2020e-05 - accuracy: 1.0000\n","Epoch 55/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 56/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.6503e-05 - accuracy: 1.0000\n","Epoch 57/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.1172e-04 - accuracy: 1.0000\n","Epoch 58/200\n","1/1 [==============================] - 0s 7ms/step - loss: 6.0150e-05 - accuracy: 1.0000\n","Epoch 59/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.9450e-05 - accuracy: 1.0000\n","Epoch 60/200\n","1/1 [==============================] - 0s 7ms/step - loss: 3.5542e-05 - accuracy: 1.0000\n","Epoch 61/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.5233e-06 - accuracy: 1.0000\n","Epoch 62/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.7042e-04 - accuracy: 1.0000\n","Epoch 63/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.6291e-05 - accuracy: 1.0000\n","Epoch 64/200\n","1/1 [==============================] - 0s 7ms/step - loss: 7.7486e-07 - accuracy: 1.0000\n","Epoch 65/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.4905e-04 - accuracy: 1.0000\n","Epoch 66/200\n","1/1 [==============================] - 0s 7ms/step - loss: 4.5155e-05 - accuracy: 1.0000\n","Epoch 67/200\n","1/1 [==============================] - 0s 12ms/step - loss: 1.1583e-05 - accuracy: 1.0000\n","Epoch 68/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.8580e-05 - accuracy: 1.0000\n","Epoch 69/200\n","1/1 [==============================] - 0s 7ms/step - loss: 7.9037e-05 - accuracy: 1.0000\n","Epoch 70/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000\n","Epoch 71/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.2716e-06 - accuracy: 1.0000\n","Epoch 72/200\n","1/1 [==============================] - 0s 7ms/step - loss: 5.2885e-04 - accuracy: 1.0000\n","Epoch 73/200\n","1/1 [==============================] - 0s 6ms/step - loss: 3.7750e-07 - accuracy: 1.0000\n","Epoch 74/200\n","1/1 [==============================] - 0s 6ms/step - loss: 8.6065e-04 - accuracy: 1.0000\n","Epoch 75/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.7815e-07 - accuracy: 1.0000\n","Epoch 76/200\n","1/1 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 1.0000\n","Epoch 77/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.7484e-06 - accuracy: 1.0000\n","Epoch 78/200\n","1/1 [==============================] - 0s 7ms/step - loss: 7.8280e-06 - accuracy: 1.0000\n","Epoch 79/200\n","1/1 [==============================] - 0s 6ms/step - loss: 5.2007e-05 - accuracy: 1.0000\n","Epoch 80/200\n","1/1 [==============================] - 0s 6ms/step - loss: 2.0642e-05 - accuracy: 1.0000\n","Epoch 81/200\n","1/1 [==============================] - 0s 7ms/step - loss: 7.9981e-05 - accuracy: 1.0000\n","Epoch 82/200\n","1/1 [==============================] - 0s 9ms/step - loss: 8.6645e-04 - accuracy: 1.0000\n","Epoch 83/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.3908e-07 - accuracy: 1.0000\n","Epoch 84/200\n","1/1 [==============================] - 0s 9ms/step - loss: 3.3776e-07 - accuracy: 1.0000\n","Epoch 85/200\n","1/1 [==============================] - 0s 6ms/step - loss: 3.5763e-07 - accuracy: 1.0000\n","Epoch 86/200\n","1/1 [==============================] - 0s 6ms/step - loss: 3.5961e-06 - accuracy: 1.0000\n","Epoch 87/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.0686e-05 - accuracy: 1.0000\n","Epoch 88/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 89/200\n","1/1 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 90/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.3404e-05 - accuracy: 1.0000\n","Epoch 91/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0218e-04 - accuracy: 1.0000\n","Epoch 92/200\n","1/1 [==============================] - 0s 7ms/step - loss: 9.9341e-08 - accuracy: 1.0000\n","Epoch 93/200\n","1/1 [==============================] - 0s 6ms/step - loss: 6.0091e-05 - accuracy: 1.0000\n","Epoch 94/200\n","1/1 [==============================] - 0s 7ms/step - loss: 6.9759e-04 - accuracy: 1.0000\n","Epoch 95/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 96/200\n","1/1 [==============================] - 0s 6ms/step - loss: 3.0276e-05 - accuracy: 1.0000\n","Epoch 97/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.2820e-04 - accuracy: 1.0000\n","Epoch 98/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.4835e-06 - accuracy: 1.0000\n","Epoch 99/200\n","1/1 [==============================] - 0s 6ms/step - loss: 2.9802e-07 - accuracy: 1.0000\n","Epoch 100/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.1337e-05 - accuracy: 1.0000\n","Epoch 101/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.5681e-05 - accuracy: 1.0000\n","Epoch 102/200\n","1/1 [==============================] - 0s 7ms/step - loss: 5.1017e-05 - accuracy: 1.0000\n","Epoch 103/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.4146e-05 - accuracy: 1.0000\n","Epoch 104/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.7819e-04 - accuracy: 1.0000\n","Epoch 105/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.5969e-04 - accuracy: 1.0000\n","Epoch 106/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.7328e-04 - accuracy: 1.0000\n","Epoch 107/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.6160e-06 - accuracy: 1.0000\n","Epoch 108/200\n","1/1 [==============================] - 0s 8ms/step - loss: 5.7618e-07 - accuracy: 1.0000\n","Epoch 109/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 110/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.4318e-05 - accuracy: 1.0000\n","Epoch 111/200\n","1/1 [==============================] - 0s 8ms/step - loss: 9.2187e-06 - accuracy: 1.0000\n","Epoch 112/200\n","1/1 [==============================] - 0s 8ms/step - loss: 8.6128e-05 - accuracy: 1.0000\n","Epoch 113/200\n","1/1 [==============================] - 0s 7ms/step - loss: 5.3246e-06 - accuracy: 1.0000\n","Epoch 114/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.2556e-05 - accuracy: 1.0000\n","Epoch 115/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.2716e-06 - accuracy: 1.0000\n","Epoch 116/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.4571e-04 - accuracy: 1.0000\n","Epoch 117/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 118/200\n","1/1 [==============================] - 0s 8ms/step - loss: 5.7618e-07 - accuracy: 1.0000\n","Epoch 119/200\n","1/1 [==============================] - 0s 9ms/step - loss: 7.7486e-07 - accuracy: 1.0000\n","Epoch 120/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.0133e-06 - accuracy: 1.0000\n","Epoch 121/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 122/200\n","1/1 [==============================] - 0s 44ms/step - loss: 2.8213e-06 - accuracy: 1.0000\n","Epoch 123/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 124/200\n","1/1 [==============================] - 0s 8ms/step - loss: 7.9473e-08 - accuracy: 1.0000\n","Epoch 125/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.4384e-05 - accuracy: 1.0000\n","Epoch 126/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.0331e-05 - accuracy: 1.0000\n","Epoch 127/200\n","1/1 [==============================] - 0s 8ms/step - loss: 6.5414e-05 - accuracy: 1.0000\n","Epoch 128/200\n","1/1 [==============================] - 0s 10ms/step - loss: 8.9604e-06 - accuracy: 1.0000\n","Epoch 129/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.9405e-06 - accuracy: 1.0000\n","Epoch 130/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.1458e-06 - accuracy: 1.0000\n","Epoch 131/200\n","1/1 [==============================] - 0s 8ms/step - loss: 6.9935e-06 - accuracy: 1.0000\n","Epoch 132/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.0205e-05 - accuracy: 1.0000\n","Epoch 133/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.5795e-05 - accuracy: 1.0000\n","Epoch 134/200\n","1/1 [==============================] - 0s 7ms/step - loss: 5.1452e-05 - accuracy: 1.0000\n","Epoch 135/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.0134e-06 - accuracy: 1.0000\n","Epoch 136/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.2052e-04 - accuracy: 1.0000\n","Epoch 137/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.0410e-04 - accuracy: 1.0000\n","Epoch 138/200\n","1/1 [==============================] - 0s 6ms/step - loss: 5.5631e-07 - accuracy: 1.0000\n","Epoch 139/200\n","1/1 [==============================] - 0s 7ms/step - loss: 4.3387e-04 - accuracy: 1.0000\n","Epoch 140/200\n","1/1 [==============================] - 0s 7ms/step - loss: 6.9802e-05 - accuracy: 1.0000\n","Epoch 141/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.2298e-05 - accuracy: 1.0000\n","Epoch 142/200\n","1/1 [==============================] - 0s 8ms/step - loss: 6.4104e-04 - accuracy: 1.0000\n","Epoch 143/200\n","1/1 [==============================] - 0s 9ms/step - loss: 5.3644e-07 - accuracy: 1.0000\n","Epoch 144/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.3483e-05 - accuracy: 1.0000\n","Epoch 145/200\n","1/1 [==============================] - 0s 7ms/step - loss: 5.7618e-07 - accuracy: 1.0000\n","Epoch 146/200\n","1/1 [==============================] - 0s 9ms/step - loss: 3.5763e-07 - accuracy: 1.0000\n","Epoch 147/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.2339e-04 - accuracy: 1.0000\n","Epoch 148/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.9780e-05 - accuracy: 1.0000\n","Epoch 149/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.2624e-04 - accuracy: 1.0000\n","Epoch 150/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.0848e-05 - accuracy: 1.0000\n","Epoch 151/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.8352e-04 - accuracy: 1.0000\n","Epoch 152/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 153/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.0747e-04 - accuracy: 1.0000\n","Epoch 154/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.6469e-04 - accuracy: 1.0000\n","Epoch 155/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.9868e-07 - accuracy: 1.0000\n","Epoch 156/200\n","1/1 [==============================] - 0s 7ms/step - loss: 8.7734e-04 - accuracy: 1.0000\n","Epoch 157/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.7815e-06 - accuracy: 1.0000\n","Epoch 158/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.3589e-05 - accuracy: 1.0000\n","Epoch 159/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.7815e-07 - accuracy: 1.0000\n","Epoch 160/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.3469e-05 - accuracy: 1.0000\n","Epoch 161/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.5100e-06 - accuracy: 1.0000\n","Epoch 162/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.8946e-05 - accuracy: 1.0000\n","Epoch 163/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.5972e-04 - accuracy: 1.0000\n","Epoch 164/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.2120e-06 - accuracy: 1.0000\n","Epoch 165/200\n","1/1 [==============================] - 0s 8ms/step - loss: 1.9471e-06 - accuracy: 1.0000\n","Epoch 166/200\n","1/1 [==============================] - 0s 9ms/step - loss: 5.2054e-06 - accuracy: 1.0000\n","Epoch 167/200\n","1/1 [==============================] - 0s 7ms/step - loss: 3.5542e-04 - accuracy: 1.0000\n","Epoch 168/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.8462e-05 - accuracy: 1.0000\n","Epoch 169/200\n","1/1 [==============================] - 0s 9ms/step - loss: 3.5763e-07 - accuracy: 1.0000\n","Epoch 170/200\n","1/1 [==============================] - 0s 10ms/step - loss: 5.1657e-07 - accuracy: 1.0000\n","Epoch 171/200\n","1/1 [==============================] - 0s 11ms/step - loss: 5.4748e-05 - accuracy: 1.0000\n","Epoch 172/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.0655e-05 - accuracy: 1.0000\n","Epoch 173/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.0943e-05 - accuracy: 1.0000\n","Epoch 174/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 1.0000\n","Epoch 175/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.9553e-04 - accuracy: 1.0000\n","Epoch 176/200\n","1/1 [==============================] - 0s 9ms/step - loss: 9.8398e-05 - accuracy: 1.0000\n","Epoch 177/200\n","1/1 [==============================] - 0s 10ms/step - loss: 6.5910e-05 - accuracy: 1.0000\n","Epoch 178/200\n","1/1 [==============================] - 0s 29ms/step - loss: 8.7021e-06 - accuracy: 1.0000\n","Epoch 179/200\n","1/1 [==============================] - 0s 33ms/step - loss: 2.5287e-04 - accuracy: 1.0000\n","Epoch 180/200\n","1/1 [==============================] - 0s 43ms/step - loss: 4.9869e-06 - accuracy: 1.0000\n","Epoch 181/200\n","1/1 [==============================] - 0s 38ms/step - loss: 4.3710e-07 - accuracy: 1.0000\n","Epoch 182/200\n","1/1 [==============================] - 0s 103ms/step - loss: 4.3710e-07 - accuracy: 1.0000\n","Epoch 183/200\n","1/1 [==============================] - 0s 6ms/step - loss: 9.9341e-08 - accuracy: 1.0000\n","Epoch 184/200\n","1/1 [==============================] - 0s 25ms/step - loss: 3.9736e-07 - accuracy: 1.0000\n","Epoch 185/200\n","1/1 [==============================] - 0s 111ms/step - loss: 3.6359e-06 - accuracy: 1.0000\n","Epoch 186/200\n","1/1 [==============================] - 0s 56ms/step - loss: 2.5829e-07 - accuracy: 1.0000\n","Epoch 187/200\n","1/1 [==============================] - 0s 8ms/step - loss: 3.0157e-05 - accuracy: 1.0000\n","Epoch 188/200\n","1/1 [==============================] - 0s 8ms/step - loss: 9.1394e-07 - accuracy: 1.0000\n","Epoch 189/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.2338e-05 - accuracy: 1.0000\n","Epoch 190/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.0663e-06 - accuracy: 1.0000\n","Epoch 191/200\n","1/1 [==============================] - 0s 9ms/step - loss: 5.4410e-05 - accuracy: 1.0000\n","Epoch 192/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.1655e-04 - accuracy: 1.0000\n","Epoch 193/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.9868e-07 - accuracy: 1.0000\n","Epoch 194/200\n","1/1 [==============================] - 0s 17ms/step - loss: 1.8125e-04 - accuracy: 1.0000\n","Epoch 195/200\n","1/1 [==============================] - 0s 13ms/step - loss: 2.7201e-04 - accuracy: 1.0000\n","Epoch 196/200\n","1/1 [==============================] - 0s 9ms/step - loss: 5.9605e-08 - accuracy: 1.0000\n","Epoch 197/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.3908e-07 - accuracy: 1.0000\n","Epoch 198/200\n","1/1 [==============================] - 0s 9ms/step - loss: 9.4571e-06 - accuracy: 1.0000\n","Epoch 199/200\n","1/1 [==============================] - 0s 9ms/step - loss: 9.4372e-06 - accuracy: 1.0000\n","Epoch 200/200\n","1/1 [==============================] - 0s 6ms/step - loss: 1.4126e-05 - accuracy: 1.0000\n"]},{"data":{"text/plain":["\u003ckeras.callbacks.History at 0x7fecf8d626a0\u003e"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["iShape = (len(x[0]),)\n","oShape = len(y[0])\n","# parameter definition\n","ourNewModel = Sequential()\n","# In the case of a simple stack of layers, a Sequential model is appropriate\n","\n","# Dense function adds an output layer\n","ourNewModel.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n","# The activation function in a neural network is in charge of converting the node's summed weighted input into activation of the node or output for the input in question\n","ourNewModel.add(Dropout(0.5))\n","# Dropout is used to enhance visual perception of input neurons\n","ourNewModel.add(Dense(64, activation=\"relu\"))\n","ourNewModel.add(Dropout(0.3))\n","ourNewModel.add(Dense(oShape, activation = \"softmax\"))\n","# below is a callable that returns the value to be used with no arguments\n","md = tensorF.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n","# Below line improves the numerical stability and pushes the computation of the probability distribution into the categorical crossentropy loss function.\n","ourNewModel.compile(loss='categorical_crossentropy',\n","              optimizer=md,\n","              metrics=[\"accuracy\"])\n","# Output the model in summary\n","print(ourNewModel.summary())\n","# Whilst training your Nural Network, you have the option of making the output verbose or simple.\n","ourNewModel.fit(x, y, epochs=200, verbose=1)\n","# By epochs, we mean the number of times you repeat a training set.\n","     "]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1673087770728,"user":{"displayName":"Reni Anggraeni","userId":"17139821022825599648"},"user_tz":-420},"id":"FUTMeNtHlSl3"},"outputs":[],"source":["def ourText(text):\n","  newtkns = nltk.word_tokenize(text)\n","  newtkns = [lm.lemmatize(word) for word in newtkns]\n","  return newtkns\n","\n","def wordBag(text, vocab):\n","  newtkns = ourText(text)\n","  bagOwords = [0] * len(vocab)\n","  for w in newtkns:\n","    for idx, word in enumerate(vocab):\n","      if word == w:\n","        bagOwords[idx] = 1\n","  return num.array(bagOwords)\n","\n","def Pclass(text, vocab, labels):\n","  bagOwords = wordBag(text, vocab)\n","  ourResult = ourNewModel.predict(num.array([bagOwords]))[0]\n","  newThresh = 0.2\n","  yp = [[idx, res] for idx, res in enumerate(ourResult) if res \u003e newThresh]\n","\n","  yp.sort(key=lambda x: x[1], reverse=True)\n","  newList = []\n","  for r in yp:\n","    newList.append(labels[r[0]])\n","  return newList\n","\n","def getRes(firstlist, fJson):\n","  tag = firstlist[0]\n","  listOfIntents = fJson[\"ourIntents\"]\n","  for i in listOfIntents:\n","    if i[\"tag\"] == tag:\n","      ourResult = random.choice(i[\"responses\"])\n","      break\n","  return ourResult"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"0rxfsHHaldK7"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 52ms/step\n","Toko kami menawarkan beberapa produk dengan kualitas baik dengan harga terjangkau, mulai dari 15.000\n","1/1 [==============================] - 0s 16ms/step\n","Toko online ini buka setiap jam 09.00 sampai 21.00\n","1/1 [==============================] - 0s 17ms/step\n","Toko online ini buka setiap jam 09.00 sampai 21.00\n","1/1 [==============================] - 0s 18ms/step\n","Toko online ini buka setiap jam 09.00 sampai 21.00\n","1/1 [==============================] - 0s 18ms/step\n","Lokasi Jl. Cisinga, Kp. Siwaru, Ds. Mekarjaya, Kec. Padakembang, Kab. Tasikmalaya\n","1/1 [==============================] - 0s 17ms/step\n","Toko online ini buka setiap jam 09.00 sampai 21.00\n","1/1 [==============================] - 0s 18ms/step\n","Toko online ini buka setiap jam 09.00 sampai 21.00\n"]}],"source":["while True:\n","    newMessage = input(\"\")\n","    intents = Pclass(newMessage, newWords, ourClasses)\n","    ourResult = getRes(intents, ourData)\n","    print(ourResult)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZE0VWWVglfbf"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOQANBHhvYZkpOe7SkIESWa","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}